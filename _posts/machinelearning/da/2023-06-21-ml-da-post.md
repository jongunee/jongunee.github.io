---
layout: post
title: sklearn 전처리
description: >
  [참조] 패스트캠퍼스 - 직장인을 위한 파이썬 데이터분석 올인원 패키지 Online.
sitemap: true
hide_last_modified: true
categories:
  - machinelearning
  - da
---

# sklearn 전처리

* toc
{:toc .large-only}

## 머신러닝이란?

- **인공지능:** 사람의 지능을 모방한 것으로 사람이 하는 일을 컴퓨터가 할 수 있도록 하는 것
- **머신러닝:** 알고리즘을 이용해 데이터를 분석 및 학습을 하고, 학습한 내용을 기반으로 판단, 예측하는 것
- **딥러닝:** 인공신경망에서 발전한 인공 지능 기술로 머신러닝 방법론 중 하나

$$인공지능 \supset 머신러닝 \supset 딥러닝$$

> 머신러닝은 한 마디로 데이터를 기반을 패턴을 학습하여 결과를 추론하는 것이라고 할 수 있다.

좋은 성능은 좋은 데이터에서 나오기 때문에 데이터를 가공하는 전처리 과정이 중요하다.

## 가설 함수, 비용, 손실 함수


먼저 가설 함수 식은 다음과 같다.

$$H(X) = W * X + b$$


| X | Y |
| --- | --- |
| 1 | 3 |
| 2 | 5 |
| 3 | 7 |

위와 같은 데이터가 있다면 예측하여 가설 함수를 세울 수가 있다.

$$H(X) = 2X + 1$$

W값과 b값에 따라 예측 값은 달라지게 될 것이고 적절한 W, b를 찾아나가는 것이 목표이다.

$$H(X) = Y Predict$$

$$손실 = Y Predict - Y$$

즉, $$손실 함수 = W * X + b - Y$$

대입해보면
$$손실함수 = 2X + 1 - Y$$

H(X)라는 가설 함수가 있을 때 손실 함수를 구하고 손실의 총합이 0으로 수렴하는 것이 최적의 해라고 할 수 있다.

만약 손실이 -1, 0, 1이 나온다면 이 또한 손실의 총합이 0이된다.
모두 0이 아니기 때문에 오류라고 할 수 있고 이를 해결하는 방법으로 MSE(Mean Squared Error)로 해결 가능하다.

$$MSE = \frac{\sum(W * X + b - Y)^2}{N}$$

음수를 없애기 위해 제곱을 해서 손실의 총합을 구하고 데이터의 개수가 많아지면 손실이 커지기 때문에 N(데이터 개수)으로 나눠주어 전체 손실의 평균을 구한다.

**경사하강법**

머신러닝의 목적은 손실을 0에 가깝도록 만드는 것이다. 즉, 손실을 0에 가깝게 만드는 최적의 W를 찾는 것이 목표라 할 수 있다.

최적의 W를 찾는 방법 중 하나가 바로 경사하강법이다.

## scikit-learn

> scikit-learn(사이킷런)이란 대표적인 파이썬 머신러닝 라이브러리로 여러 머신러닝 알고리즘과 데이터 셋 등을 포함하고 있다.

**불러오기**

```py
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_teste_split
```

**모델 정의**

```py
model=LinearRegression()
```

**학습 - fit**

```py
model.fit(x, y)
```

**예측 - predict**

```py
prediction = model.predict(x2)
```

## 예측 예시

```py
import numpy as np
from sklearn.linear_model import LinearRegression

x = np.arange(10).reshape(-1, 1)
y = (2*x + 1).reshape(-1, 1)

# 모델 선언
model = LinearRegression()
# 학습
model.fit(x, y)
# 예측
prediction = model.predict([[10.0]])
print(prediction)
```

- x에 0 ~ 9의 데이터 배열 생성
- y에 1, 3, 5, ..., 19의 데이터 배열 생성
- 선형회귀 모델을 불러와서 학습 후 예측

## 학습데이터와 예측 데이터

```py
model.fit(x,y)
```

**x**
- features라고 부름
- 학습에 넣을 데이터로 **x_train**, **x_test** 변수를 사용
- 학습을 위한 데이터셋이 담겨 있으며 예측을 해야하는 값은 제외
- ex) 지역, 평 수, 동네 등등

**y**
- labels라고 부름
- **y_train**, **y_test** 변수 사용
- 예측해야할 값으로 예측 값만 존재
- ex) 집 값

**Training Set**

- 학습을 위한 데이터
- 모델이 학습하기 위해 필요한 데이터
- feature/label 모두 존재

**Test Set**

- 예측을 위한 데이터
- 모델이 예측하기 위한 데이터
- feature만 존재

```py
model.fit(x_train, y_train)
prediction = model.predict(x_test)
```

**x_train**, **y_train** 값을 통해 예측을 하고 **x_test** 값을 넣어 나온 예측값(prediciton)을 **y_test**와 비슷하게 나왔는지 비교하는 것이 동작 방식이다.

## 검증 데이터

**Overfitting(과적합)**

> 과적합이란 학습한 데이터에만 적합하게, 과도하게 학습이 되어 내가 가진 데이터가 아닌 데이터가 들어왔을 때 성능이 떨어져 일반적인 예측을 할 수 없는 상태를 말한다.

**Underfitting(과소적합)**

> 과소적합이란 학습이 제대로 되지 않아 제대로 예측을 하지 못하는 상태를 말한다.

**Optimum(최적화)**

> 약간의 오차는 있더라도 학습이 잘 되어 최적화된 성능을 보여주는 상태를 말한다.

**Training Error** 보다 **Validation Error**가 더 커지는 지점이 과적합이 발생하는 지점이기 때문에 이 시점을 잘 찾아내야 한다.

따라서 주로 **Training Set** 중 80%는 학습을 위한 데이터로 사용하고 20%는 검증을 위한 데이터(**Validation Set**)로 사용한다.

학습시 절대로 Validation Set이 관여, 섞이면 안된다.

## 전처리(pre-processing)

> 전처리란 데이터 분석에 적합하게 데이터를 가공/변형/처리/클리닝 하는 것을 말한다.

- 결측치(Imputer)
- 이상치
- 정규화(Normalization)
- 표준화(Standardization)
- 샘플링(Over/Under sampliing)
- 피처공학(Feature Engineering)
  - feature 생성/연산
  - 구간 생성, 스케일 변형 등

타이타닉 데이터셋을 통해 전처리를 진행해본다.

### Train/Validation Set 나누기

- Feature 정의
  ```py
  feature = [
    'Pclass', 'Sex', 'Age', 'Fare'
  ]
  ```

- Label 정의
  ```py
  label = [
    'Survived'
  ]
  ```

- `train_test_split` 불러오기
  ```py
  from sklearn.model_selection import train_test_split
  ```
  - test_size: Validation Set에 할당할 비율 (20%라면 0.2)
  - shuffle: 셔플 옵션 (Default 값 True)
  - random_state: 랜덤 시드값

- 데이터 return
  ```py
  x_train, x_valid, y_train, y_valid = train_test_split(train[feature], train[label], test_size=0.2, shuffle=True, random_state=30)
  ```
  이 때 리턴받는 데이터 순서가 중요하다.

### 결측치

- 결측치 확인
  ```py
  train.info()
  ```
  ```py
  train.isnull().sum()
  ```
  합계를 보면 한 눈에 확인하기 쉽다

### 수치형(Numerical) 데이터 결측치 처리

- 결측값 0으로 처리
  ```py
  train['Age'].fillna(0).describe()
  ```

- 결측값 평균값으로 처리
  ```py
  train['Age'].fillna(train['Age'].mean()).describe()
  ```

### imputer로 2개 이상의 column 처리  

- 필요한 함수를 불러오기
  ```py
  from sklearn.impute import SimpleImputer
  ```
- 결측값은 평균값으로 처리하도록 strategy 설정
  ```py
  imputer = SimpleImputer(strategy='mean')
  ```
- 결측치에 대한 학습
  ```py
  imputer.fit(train[['Age', 'Pclass']])
  ```
- 결측치 처리
  ```py
  result = imputer.transform(train[['Age', 'Pclass']])
  ```
- fit_transform  
  위 `fit()`, `transform()` 함수를 한 번해 처리 해주는 함수이다.
  ```py
  imputer = SimpleImputer(strategy='median')
  ```
  strategy 설정만 해주고 바로 한 번에 처리가 가능하다.
  ```py
  result = imputer.fit_transform(train[['Age', 'Pclass']])
  ```

### 문자형(Categorical) 데이터 결측치 처리 - 1개의 column

  ```py
  train['Embarked'].fillna('S')
  ```

### 문자형(Categorical) 데이터 결측치 처리 - 2개 이상의 column
 
- strategy 설정
  ```py
  imputer = SimpleImputer(strategy='most_frequent')
  ```

- 결측치 처리
  ```py
  result = imputer.fit_transform(train[['Embarked', 'Cabin']])
  ```

- 처리값 대입
  ```py
  train[['Embarked', 'Cabin']] = result
  ```





















<span style="font-size:70%">[참조] 패스트캠퍼스 - 직장인을 위한 파이썬 데이터분석 올인원 패키지 Online.</span>

끝!
