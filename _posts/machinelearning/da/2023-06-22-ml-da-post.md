---
layout: post
title: sklearn 전처리2
description: >
  [참조] 패스트캠퍼스 - 직장인을 위한 파이썬 데이터분석 올인원 패키지 Online.
sitemap: true
hide_last_modified: true
categories:
  - machinelearning
  - da
---

# sklearn 전처리2

* toc
{:toc .large-only}

## Label Encoder

Label Encoding은 문자(categorical)를 수치(numerical)로 변환하는 것을 말하며 학습을 위해 모든 문자로 된 데이터는 Label Encoding이 필요하다.

```py
train.info()
```
확인하여 `object` 타입으로 나오는 모든 데이터는 문자형 데이터라고 볼 수 있다.

이 중 성별 데이터를 숫자형 데이터로 바꿔보기로 한다.

- 함수 정의
  ```py
  def convert(data):
    if data == 'male':
        return 1
    elif data == 'female':
        return 0
  ```

- 함수 적용하여 변환
  ```py
  train['Sex'].apply(convert)
  ```

위 방법도 있지만 Label Encoder를 이용할 수도 있다.

- 함수 불러오기
  ```py
  from sklearn.preprocessing import LabelEncoder
  le = LabelEncoder()
  ```

- 데이터 변환
  ```py
  train['Sex_num'] = le.fit_transform(train['Sex'])
  ```

- 클래스 확인
  ```py
  le.classes_
  ```
  다음과 같이 결과를 보여주어 변환 데이터 종류를 확인할 수 있다. 
  ```
  array(['female', 'male'], dtype=object)
  ```

- NaN 값 포함시 LabelEncoder 동작
  ```py
  le.fit_transform(train['Embarked'])
  ```
  NaN 값이 존재하면 LabelEncoder는 오류가 발생하기 때문에 

  ```py
  train['Embarked'] = train['Embarked'].fillna('S')
  ```
  결측값을 채우는 작업이 필요하다.

## 원 핫 인코딩(One Hot Encoding)

- 데이터 종류 확인
  ```py
  train['Embarked'].value_counts()
  ```

  ```
  S    644
  C    168
  Q     77
  Name: Embarked, dtype: int64
  ```

- 결측값 채우기
  ```py
  train['Embarked'] = train['Embarked'].fillna('S')
  ```

- Label Encoding
  ```py
  train['Embarked_num'] = LabelEncoder().fit_transform(train['Embarked'])
  train['Embarked_num'].value_counts()
  ```
  ```
  2    646
  0    168
  1     77
  Name: Embarked_num, dtype: int64
  ```
  이처럼 문자형 데이터가 숫자형 데이터로 바뀐다.

하지만 이 데이터를 그대로 사용하게 되면 'S'는 2, Q는 1이라는 정보를 통해 Q + Q = S라는 식으로 학습을 해버리게 된다. 따라서 원 핫 인코딩을 통해 각 데이터에 대해 독립성을 부여한다.

- 원 핫 인코딩
  ```py
  one_hot = pd.get_dummies(train['Embarked_num'][:6])
  ```

- column 명 변경
  ```py
  one_hot.columns = ['C','Q','S']
  ```

- 결과 확인

  | | C |	Q |	S |
  | --- | --- | --- | --- |
  | 0 |	0	| 0 |	1 |
  | 1 | 1 | 0 |	0 |
  | 2 | 0 | 0 |	1 |
  | 3 | 0 | 0 |	1 |
  | 4 | 0 | 0 |	1 |
  | 5 | 0 | 1 |	0 |

## 정규화(Normalize)

> 정규화란 column 간에 다른 min, max 값을 가지는 경우, 정규화를 통해 최소치/최대값의 척도를 맞춰주는 것이다.

- 네이버 영화평점 (0점 ~ 10점): [2, 4, 6, 8, 10]
- 넷플릭스 영화평점 (0점 ~ 5점): [1, 2, 3, 4, 5]

위 같은 경우 범위가 다르기 때문에 그대로 데이터를 분석한다면 잘못된 학습 결과를 얻게 될 것이고 이때 정규화가 사용된다.

- 함수 불러오기
  ```py
  from sklearn.preprocessing import MinMaxScaler
  ````
- MinMaxScaler 선언
  ```py
  min_max_scaler = MinMaxScaler()
  ```
- MinMaxScaler에 데이터 대입
  ```py
  min_max_movie = min_max_scaler.fit_transform(movie)
  ```
- 결과 확인
  ```py
  pd.DataFrame(min_max_movie, columns=['naver', 'netflix'])
  ```

  | | naver | netflix |
  | --- | --- | --- |
  | 0	| 0.00 | 0.00 |
  | 1	| 0.25 | 0.25 |
  | 2	| 0.50 | 0.50 |
  | 3	| 0.75 | 0.75 |
  | 4	| 1.00 | 1.00 |


## 표준화(Standard Scaling)

> 표준화란 평균이 0, 표준편차가 1이 되도록 변환하는 것이다.

- StandardScaler 불러오기 및 선언

  ```py
  from sklearn.preprocessing import StandardScaler
  standard_scaler = StandardScaler()
  ```

- 샘플 데이터 생성

  ```py
  x = np.arange(10)
  ```
- outlier 추가
  ```py
  x[9] = 1000
  ```
- 평균, 표준편차 확인
  ```py
  x.mean(), x.std()
  ```
  값이 큰 outlier가 존재하기 때문에 다음과 같이 값이 굉장히 커진다.
  ```
  (103.6, 298.8100399919654)
  ```
- StandardScaler 적용
  ```py
  scaled = standard_scaler.fit_transform(x.reshape(-1, 1))
  ```
- 평균, 표준편차 확인
  ```py
  scaled.mean(), scaled.std()
  ```
  ````
  (4.4408920985006264e-17, 1.0)
  ```
- 반올림
  위 값은 매우 작은 값이지만 알아보기 어렵기 때문에 반올림을 해준다.
  ```py
  round(scaled.mean(), 2), scaled.std()
  ```
  ```
  (0.0, 1.0)
  ```
  이렇게 평균이 0, 표준편차가 1로 표준화가 된 것을 확인할 수 있다. 
  

<span style="font-size:70%">[참조] 패스트캠퍼스 - 직장인을 위한 파이썬 데이터분석 올인원 패키지 Online.</span>

끝!
